{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CoNIC2022_compute_stats.ipynb","provenance":[{"file_id":"https://github.com/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/StarDist_2D_ZeroCostDL4Mic.ipynb","timestamp":1643052785088}],"collapsed_sections":[],"machine_shape":"hm"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IkSguVy8Xv83"},"source":["# **CoNIC 2022 Compute Stats**\n","---\n","\n","<font size = 4> Notebook adapted from the code https://github.com/TissueImageAnalytics/CoNIC"]},{"cell_type":"markdown","metadata":{"id":"XuwTHSva_Y5K"},"source":["## **1.1. Install key dependencies**\n","---\n","<font size = 4> "]},{"cell_type":"code","metadata":{"id":"fq21zJVFNASx","cellView":"form"},"source":["#@markdown ##Install dependencies\n","\n","# Install packages which are not included in Google Colab\n","\n","#!pip install docopt \n","#!pip install numpy \n","#!pip install pandas\n","#!pip install tqdm\n","#!pip install scipy\n","#!pip install sklearn\n","\n","#Force session restart\n","#exit(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"01Djr8v-5pPk","cellView":"form"},"source":["#@markdown ##Play the cell to connect your Google Drive to Colab\n","\n","#@markdown * Click on the URL. \n","\n","#@markdown * Sign in your Google Account. \n","\n","#@markdown * Copy the authorization code. \n","\n","#@markdown * Enter the authorization code. \n","\n","#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\". \n","\n","# mount user's Google Drive to Google Colab.\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/gdrive/MyDrive/metrics/')\n","sys.path.append('/content/gdrive/MyDrive/mics/')"],"metadata":{"id":"vkcFXm0Votsh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from docopt import docopt\n","import numpy as np\n","import os\n","import pandas as pd\n","from tqdm.auto import tqdm\n","\n","from gdrive.MyDrive.misc.utils import remap_label, get_bounding_box\n","from gdrive.MyDrive.metrics.stats_utils import get_pq, get_multi_pq_info, get_multi_r2"],"metadata":{"id":"PnG-LYWCo-v4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Segmentation & classification: multi-class panoptic quality (mPQ+)**\n","\n","To appropriately calculate the metrics, ensure that your output is in the following format:\n","- .npy array of size Nx256x256x2, where N is the number of processed patches.\n","- First channel is the instance segmentation map containing values ranging from 0 (background) to n (number of nuclei).\n","- Second channel is the classification map containing values ranging from 0 (background) to 6 (number of classes in the dataset)."],"metadata":{"id":"GzlJDn941uiF"}},{"cell_type":"code","source":["# https://github.com/TissueImageAnalytics/CoNIC\n","# To get the stats for segmentation and classification, run:\n","\n","# python compute_stats.py --mode=\"seg_class\" --pred=<path_to_results> --true=<path_to_ground_truth>\n","# To get the stats for cellular composition prediction, run:\n","\n","# python compute_stats.py --mode=\"regression\" --pred=<path_to_results> --true=<path_to_ground_truth>\n","\n","#\"regression\" or \"seg_class\"\n","mode = [\"--mode\"]\n","pred_array = np.load('../content/gdrive/MyDrive/Predictions/labels_0_100.npy')\n","true_array = np.load('../content/gdrive/MyDrive/Ground_Truth/labels_0_100.npy')\n","#seg_metrics_names = [\"pq\"]\n","seg_metrics_names = [\"pq\", \"multi_pq+\"]\n","reg_metrics_names = [\"r2\"]"],"metadata":{"id":"LZQz9_5ZydfF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Skip if no data cropping\n","# Select only images n to m\n","#pred_array = pred_array[1000:1050,:,:,:]\n","#true_array = true_array[1000:1050,:,:,:]"],"metadata":{"id":"WdERKoAiyeKo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nr_patches = pred_array.shape[0]"],"metadata":{"id":"a2ejUFC7zskW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_metrics = {}\n","pq_list = []\n","mpq_info_list = []"],"metadata":{"id":"NzH2DZ2Cz08Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for patch_idx in tqdm(range(nr_patches)):\n","    # get a single patch\n","    pred = pred_array[patch_idx]\n","    true = true_array[patch_idx]\n","    # instance segmentation map\n","    pred_inst = pred[..., 0]\n","    true_inst = true[..., 0]\n","    # classification map\n","    pred_class = pred[..., 1]\n","    true_class = true[..., 1]\n","    \n","    for idx, metric in enumerate(seg_metrics_names):\n","        if metric == \"pq\":\n","            # get binary panoptic quality\n","            pq = get_pq(true_inst, pred_inst)\n","            pq = pq[0][2]\n","            pq_list.append(pq)\n","        elif metric == \"multi_pq+\":\n","            # get the multiclass pq stats info from single image\n","            mpq_info_single = get_multi_pq_info(true, pred)\n","            mpq_info = []\n","            # aggregate the stat info per class\n","            for single_class_pq in mpq_info_single:\n","                tp = single_class_pq[0]\n","                fp = single_class_pq[1]\n","                fn = single_class_pq[2]\n","                sum_iou = single_class_pq[3]\n","                mpq_info.append([tp, fp, fn, sum_iou])\n","            mpq_info_list.append(mpq_info)\n","        else:\n","            raise ValueError(\"%s is not supported!\" % metric)"],"metadata":{"id":"MUCS_0X5z1cD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pq_metrics = np.array(pq_list)\n","pq_metrics_avg = np.mean(pq_metrics, axis=-1)  # average over all images\n","if \"multi_pq+\" in seg_metrics_names:\n","    mpq_info_metrics = np.array(mpq_info_list, dtype=\"float\")\n","    # sum over all the images\n","    total_mpq_info_metrics = np.sum(mpq_info_metrics, axis=0)"],"metadata":{"id":"4NWiHGR_z1q6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for idx, metric in enumerate(seg_metrics_names):\n","    if metric == \"multi_pq+\":\n","        mpq_list = []\n","        # for each class, get the multiclass PQ\n","        for cat_idx in range(total_mpq_info_metrics.shape[0]):\n","            total_tp = total_mpq_info_metrics[cat_idx][0]\n","            total_fp = total_mpq_info_metrics[cat_idx][1]\n","            total_fn = total_mpq_info_metrics[cat_idx][2]\n","            total_sum_iou = total_mpq_info_metrics[cat_idx][3]\n","\n","            # get the F1-score i.e DQ\n","            dq = total_tp / (\n","                (total_tp + 0.5 * total_fp + 0.5 * total_fn) + 1.0e-6\n","            )\n","            # get the SQ, when not paired, it has 0 IoU so does not impact\n","            sq = total_sum_iou / (total_tp + 1.0e-6)\n","            mpq_list.append(dq * sq)\n","        mpq_metrics = np.array(mpq_list)\n","        all_metrics[metric] = [np.mean(mpq_metrics)]\n","    else:\n","        all_metrics[metric] = [pq_metrics_avg]"],"metadata":{"id":"O8jAnceQz14Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(all_metrics)\n","df = df.to_string(index=False)\n","print(df)"],"metadata":{"id":"WGJcdwd-z_4f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Predicting cellular composition: multi-class coefficient of determination (R2)**\n","Single .csv file where the column headers should be:\n","- neutrophil\n","- epithelial\n","- lymphocyte\n","- plasma\n","- eosinophil\n","- connective\n","\n","To make sure the calculation is done correctly, ensure that the row ordering is the same for both the ground truth and prediction csv files."],"metadata":{"id":"AnqaMfZ80q6r"}},{"cell_type":"code","source":["pred_csv = pd.read_csv('../content/gdrive/MyDrive/Predictions/counts.csv')\n","true_csv = pd.read_csv('../content/gdrive/MyDrive/Ground_Truth/counts.csv')"],"metadata":{"id":"ixEk8kfz0ARa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Select only rows n to m\n","pred_csv = pred_csv.iloc[100:1000]\n","true_csv = true_csv.iloc[100:1000]"],"metadata":{"id":"gL-314zo0Ae5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for idx, metric in enumerate(reg_metrics_names):\n","    if metric == \"r2\":\n","        # calculate multiclass coefficient of determination\n","        r2 = get_multi_r2(true_csv, pred_csv)\n","        all_metrics[\"multi_r2\"] = [r2]\n","    else:\n","        raise ValueError(\"%s is not supported!\" % metric)"],"metadata":{"id":"gKD6JmyI0Asn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(all_metrics)\n","df = df.to_string(index=False)\n","print(df)"],"metadata":{"id":"3aAdXqrA03gi"},"execution_count":null,"outputs":[]}]}